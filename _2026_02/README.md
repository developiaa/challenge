# ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
ì´ êµ¬ì¡°ì˜ í•µì‹¬ì€ ì“°ê¸°(Command)ëŠ” MySQL ìƒ¤ë“œì— ì§‘ì¤‘í•˜ê³ , ì¡°íšŒ(Query)ëŠ” ê³ ì† ê²€ìƒ‰ ì—”ì§„ì—ì„œ ìˆ˜í–‰í•˜ì—¬ ë™ê¸°í™” ì§€ì—°ì„ í—ˆìš©í•˜ëŠ” ìµœì¢… ì¼ê´€ì„±(Eventual Consistency) ëª¨ë¸

1. Transaction (Source)
- í–‰ë™: ì‚¬ìš©ìê°€ ProductService.saveProductComposite()ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
- ê²°ê³¼: ìƒ¤ë”© ì „ëµì— ë”°ë¼ ds-0, ds-1, ds-2 ì¤‘ í•˜ë‚˜ì˜ MySQLì— ë°ì´í„°ê°€ INSERT/UPDATE ë©ë‹ˆë‹¤.
- í•µì‹¬: ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì˜¤ì§ DBì—ë§Œ ì§‘ì¤‘í•©ë‹ˆë‹¤. Kafkaì— ë©”ì‹œì§€ë¥¼ ë³´ë‚´ëŠ” ì½”ë“œëŠ” ë‹¨ í•œ ì¤„ë„ ì—†ìŠµë‹ˆë‹¤. (Dual Write ë¬¸ì œ í•´ê²°)

2. Binlog Recording (MySQL)
- í–‰ë™: MySQLì€ ì»¤ë°‹ëœ íŠ¸ëœì­ì…˜ì„ Binary Log (Binlog) íŒŒì¼ì— ìˆœì°¨ì ìœ¼ë¡œ ê¸°ë¡í•©ë‹ˆë‹¤.
- í•µì‹¬: ì´ Binlogê°€ ë°”ë¡œ "ì§„ì‹¤ì˜ ì›ì²œ(Source of Truth)"ì´ì ë³€ê²½ ì´ë ¥ì„œì…ë‹ˆë‹¤.


3. Capture & Stream (Debezium)
- í–‰ë™: Debezium ì»¤ë„¥í„°(inventory-connector-X)ëŠ” MySQLì— **"ë…¸ì˜ˆ ì„œë²„(Slave replica)"**ì¸ ì²™ ìœ„ì¥í•˜ê³  ì ‘ì†í•©ë‹ˆë‹¤.
- ê³¼ì •: MySQLì€ "ìƒˆë¡œìš´ ìŠ¬ë ˆì´ë¸Œê°€ ì™”ë„¤?" í•˜ê³  Binlog ìŠ¤íŠ¸ë¦¼ì„ Debeziumì—ê²Œ ì´ì¤ë‹ˆë‹¤.
- ë³€í™˜: Debeziumì€ ì´ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ í•´ì„í•´ì„œ JSON í¬ë§·(before, after êµ¬ì¡°)ìœ¼ë¡œ ë°”ê¾¼ ë’¤, ì§€ì •ëœ Kafka Topic(shard0...)ìœ¼ë¡œ ì˜ì•„ ë³´ëƒ…ë‹ˆë‹¤.
- í˜„ì¬ ìƒíƒœ: ì—¬ê¸°ê¹Œì§€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! Kafkaì— ë°ì´í„°ê°€ ìŒ“ì—¬ ìˆìŠµë‹ˆë‹¤.

4. Consume & Indexing
- í–‰ë™: Spring Boot Consumerê°€ Kafka í† í”½ 3ê°œë¥¼ êµ¬ë…(shard*.products)í•©ë‹ˆë‹¤.
- ë¡œì§: ë©”ì‹œì§€ê°€ ì˜¤ë©´ after ë°ì´í„°ë¥¼ êº¼ë‚´ì„œ Elasticsearchì— upsert(ì—†ìœ¼ë©´ ì…ë ¥, ìˆìœ¼ë©´ ìˆ˜ì •) í•©ë‹ˆë‹¤.
- ê²°ê³¼: ì‚¬ìš©ìëŠ” "ìƒí’ˆëª… ê²€ìƒ‰" ìš”ì²­ì„ MySQLì´ ì•„ë‹Œ Elasticsearchë¡œ ë‚ ë ¤ì„œ, ìƒ¤ë“œ ìƒê´€ì—†ì´ 0.1ì´ˆ ë§Œì— ê²°ê³¼ë¥¼ ì–»ìŠµë‹ˆë‹¤.

ğŸ’¡ ì™œ ì´ êµ¬ì¡°ë¥¼ ì¼ëŠ”ê°€?
- ê²°í•©ë„ ì œê±° (Decoupling): ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì— kafkaTemplate.send()ê°€ ì„ì—¬ ìˆìœ¼ë©´, Kafka ì¥ì•  ì‹œ íŠ¸ëœì­ì…˜ ë¡¤ë°± ì—¬ë¶€ê°€ ì• ë§¤í•´ì§‘ë‹ˆë‹¤. ì´ êµ¬ì¡°ëŠ” DB íŠ¸ëœì­ì…˜ê³¼ ë©”ì‹œì§€ ë°œí–‰ì„ ì™„ë²½íˆ ë¶„ë¦¬í•©ë‹ˆë‹¤.
- ë°ì´í„° ìœ ì‹¤ ì œë¡œ (Zero Data Loss): ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ì—ì„œ ì´ë²¤íŠ¸ë¥¼ ì˜ë‹¤ê°€ ì„œë²„ê°€ ì£½ìœ¼ë©´ ì´ë²¤íŠ¸ê°€ ìœ ì‹¤ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ BinlogëŠ” DBê°€ ì»¤ë°‹í–ˆë‹¤ë©´ ë¬´ì¡°ê±´ ì¡´ì¬í•˜ë¯€ë¡œ, Debeziumì´ ì–¸ì œë“  ë‹¤ì‹œ ì½ì–´ì„œ ë³µêµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ìµœì¢… ì¼ê´€ì„± (Eventual Consistency): ìƒ¤ë”©ëœ DB í™˜ê²½ì—ì„œ "ì „ì²´ ì¡°íšŒ(Global Query)"ëŠ” ë¶ˆê°€ëŠ¥ì— ê°€ê¹ìŠµë‹ˆë‹¤. ì•½ê°„ì˜ ë”œë ˆì´(ìˆ˜ë°± ms)ë¥¼ ê°ìˆ˜í•˜ê³  ì¡°íšŒ ì „ìš© DB(Elasticsearch)ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì˜ ì •ì„ì…ë‹ˆë‹¤.

```mermaid
graph TD
%% ë…¸ë“œ ìŠ¤íƒ€ì¼ ì •ì˜
    classDef client fill:#f9f,stroke:#333,stroke-width:2px,color:black;
    classDef app fill:#d4e1f5,stroke:#333,stroke-width:2px,color:black;
    classDef db fill:#e1f5fe,stroke:#333,stroke-width:2px,color:black;
    classDef kafka fill:#fff3e0,stroke:#333,stroke-width:2px,color:black;
    classDef es fill:#e8f5e9,stroke:#333,stroke-width:2px,color:black;

%% 1. Command Phase
    Client((User / Client)) -->|1. POST /products| APIServer["Spring Boot API Server<br/>(Write / Command)"]

    subgraph "Application Layer"
        APIServer -->|2. Routing Strategy| ShardingRouter{Sharding Router}
    end

    subgraph "Data Persistence Layer (Sharded MySQL)"
        ShardingRouter -->|"Category: Elec"| DB0[("DS-0: MySQL<br/>Shard 0")]
        ShardingRouter -->|"Category: Book"| DB1[("DS-1: MySQL<br/>Shard 1")]
        ShardingRouter -->|"Category: Fashion"| DB2[("DS-2: MySQL<br/>Shard 2")]
    end

%% 2. CDC Phase
    subgraph "CDC Layer (Debezium Connect)"
        DB0 -.->|3. Binlog| Connector0["Inventory Connector 0"]
        DB1 -.->|3. Binlog| Connector1["Inventory Connector 1"]
        DB2 -.->|3. Binlog| Connector2["Inventory Connector 2"]
    end

%% 3. Streaming Phase
    subgraph "Event Streaming Layer (Kafka)"
        Connector0 -->|4. Produce JSON| Topic0("Topic: shard0.products")
        Connector1 -->|4. Produce JSON| Topic1("Topic: shard1.products")
        Connector2 -->|4. Produce JSON| Topic2("Topic: shard2.products")
    end

%% 4. Indexing Phase
    subgraph "Indexing Layer"
        Topic0 & Topic1 & Topic2 -->|"5. Consume & Parse"| Consumer["Spring Boot Consumer<br/>(Sync Worker)"]
        Consumer -->|"6. Upsert / Delete"| ES[("Elasticsearch<br/>Query Engine")]
    end

%% 5. Query Phase
    Client -.->|"7. GET /search (Fast)"| ES

%% ìŠ¤íƒ€ì¼ ì ìš©
    class Client client;
    class APIServer,Consumer app;
    class DB0,DB1,DB2 db;
    class Topic0,Topic1,Topic2,Connector0,Connector1,Connector2 kafka;
    class ES es;
```
ğŸ”„ ë°ì´í„° íë¦„ ìƒì„¸ ì„¤ëª…
1. Command Phase (ì“°ê¸° ìš”ì²­)
- ì£¼ì²´: ì‚¬ìš©ì -> Spring Boot (API Server)
- ë™ì‘: ProductService.saveProductComposite() í˜¸ì¶œ.
- ë¡œì§: ì• í”Œë¦¬ì¼€ì´ì…˜ ë‚´ë¶€ì˜ AbstractRoutingDataSourceê°€ ì¹´í…Œê³ ë¦¬(Sharding Key)ë¥¼ ë¶„ì„í•˜ì—¬ ds-0, ds-1, ds-2 ì¤‘ í•˜ë‚˜ë¡œ íŠ¸ëœì­ì…˜ì„ ë¼ìš°íŒ…í•©ë‹ˆë‹¤.
- íŠ¹ì§•: ì´ ë‹¨ê³„ì—ì„œëŠ” Kafkaë‚˜ Elasticsearchë¥¼ ì „í˜€ ì‹ ê²½ ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜¤ì§ DB ì €ì¥ ì„±ê³µ ì—¬ë¶€ë§Œ ì¤‘ìš”í•©ë‹ˆë‹¤.

2. CDC Phase (ë³€ê²½ ê°ì§€)
- ì£¼ì²´: MySQL Binlog -> Debezium Connector
- ë™ì‘: DBì— INSERT/UPDATE/DELETEê°€ ì»¤ë°‹ë˜ëŠ” ì¦‰ì‹œ, Debeziumì´ Binlogë¥¼ ì½ì–´ JSON ì´ë²¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
- íŠ¹ì§•: ì• í”Œë¦¬ì¼€ì´ì…˜ ë¶€í•˜ ì—†ì´ ë¹„ë™ê¸°ë¡œ ì‘ë™í•˜ë©°, Delete Tombstone(ì‚­ì œ ë§ˆí‚¹) ì²˜ë¦¬ë„ ì—¬ê¸°ì„œ ìˆ˜í–‰ë©ë‹ˆë‹¤.

3. Streaming Phase (ì´ë²¤íŠ¸ ì „ì†¡)
- ì£¼ì²´: Debezium -> Kafka Topics
- ë™ì‘: shard0..., shard1... ë“±ì˜ í† í”½ìœ¼ë¡œ ë°ì´í„°ê°€ ë°œí–‰ë©ë‹ˆë‹¤.
- íŠ¹ì§•: ìˆœì„œ ë³´ì¥(Ordering)ì„ ìœ„í•´ íŒŒí‹°ì…”ë‹ ì „ëµì´ ì¤‘ìš”í•˜ë©°, ë°ì´í„°ê°€ ìœ ì‹¤ë˜ì§€ ì•ŠëŠ” ë²„í¼ ì—­í• ì„ í•©ë‹ˆë‹¤.

4. Indexing Phase (ë™ê¸°í™”)
- ì£¼ì²´: Kafka -> Spring Boot Consumer -> Elasticsearch
- ë™ì‘: ProductSyncConsumerê°€ ë©”ì‹œì§€ë¥¼ ìˆ˜ì‹ í•©ë‹ˆë‹¤.
- op='c', 'u': Elasticsearchì— index(ì €ì¥/ìˆ˜ì •) ìš”ì²­.
- op='d': Elasticsearchì— delete ìš”ì²­.
- payload=null: íˆ¼ìŠ¤í†¤ ë©”ì‹œì§€ëŠ” ë¬´ì‹œ(Skip).

5. Query Phase (ì½ê¸° ìš”ì²­ - Next Step)
-  ì£¼ì²´: ì‚¬ìš©ì -> Elasticsearch
- ë™ì‘: "ë§¥ë¶"ì„ ê²€ìƒ‰í•˜ë©´ ìƒ¤ë”©ëœ DB 3ê°œë¥¼ ë’¤ì§€ëŠ” ê²Œ ì•„ë‹ˆë¼, ë‹¨ í•˜ë‚˜ì˜ Elasticsearch ì¸ë±ìŠ¤ë¥¼ ì¡°íšŒí•˜ì—¬ 0.1ì´ˆ ì•ˆì— ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

# Debeziumì„ ì´ìš©í•œ ì‹¤ì‹œê°„ CDC(Change Data Capture) êµ¬ì¶• ê°€ì´ë“œ
- Debeziumì€ MySQLì˜ Binlogë¥¼ ì½ì–´ì„œ ì‘ë™í•©ë‹ˆë‹¤. í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ MySQL ì»¨í…Œì´ë„ˆë“¤ì´ Binlogë¥¼ ROW í¬ë§·ìœ¼ë¡œ ê¸°ë¡í•˜ë„ë¡ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
- initdb/setup.sql ë˜ëŠ” ê° DBì— ì ‘ì†í•˜ì—¬ ì‹¤í–‰: CDC ì „ìš© ê³„ì •ì„ ìƒì„±í•˜ê³  ê¶Œí•œì„ ë¶€ì—¬í•©ë‹ˆë‹¤.


# Debezium ì„¤ì •
Debezium(Kafka Connect)ì€ ê¸°ë³¸ì ìœ¼ë¡œ ë©”ì‹œì§€ì— **ë°ì´í„°ì˜ ìŠ¤í‚¤ë§ˆ ì •ë³´(Schema)**ë¥¼ í¬í•¨í•´ì„œ ë³´ëƒ…ë‹ˆë‹¤.
- value.converter.schemas.enable=true (ê¸°ë³¸ê°’)
```json
{
  "schema": { ... },   // ìŠ¤í‚¤ë§ˆ ì •ë³´ (í•„ë“œ íƒ€ì… ë“±)
  "payload": {         // ì‹¤ì œ ë°ì´í„°
    "before": { ... },
    "after": { ... },
    "source": { ... },
    "op": "c"
  }
}
```

- value.converter.schemas.enable=false (ì‹¤ë¬´ ê¶Œì¥)
```json
{
  "before": { ... },
  "after": { ... },
  "source": { ... },
  "op": "c"
}
```

- SMT (êµ¬ì¡° ë³€ê²½ ì˜µì…˜) ì‚¬ìš© ì—¬ë¶€
ë§Œì•½ Debezium ì»¤ë„¥í„° ì„¤ì •ì— ExtractNewRecordState ê°™ì€ SMTë¥¼ ì ìš©í–ˆë‹¤ë©´, ë³µì¡í•œ before, op, sourceë¥¼ ë‹¤ ë‚ ë¦¬ê³  ìˆœìˆ˜í•˜ê²Œ after ë°ì´í„°ë§Œ í‰í‰í•˜ê²Œ(Flatten) ë³´ëƒ…ë‹ˆë‹¤.


# docker ì‹¤í–‰ í›„ ìƒ¤ë“œ ë“±ë¡
- mysql ì»¨í…Œì´ë„ˆë§ˆë‹¤ ë“±ë¡í•´ì£¼ì–´ì•¼í•¨
- database.hostname, database.server.id, topic.prefix, schema.history.internal.kafka.topic ê°€ ë‹¬ë¼ì•¼í•¨

1ë²ˆ ìƒ¤ë“œ
```http request
curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" localhost:8083/connectors/ -d '{
  "name": "inventory-connector-0",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "tasks.max": "1",
    "database.hostname": "mysql-3308", 
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "dbz",
    "database.server.id": "5001",
    "topic.prefix": "shard0",
    "database.include.list": "products",
    "schema.history.internal.kafka.bootstrap.servers": "kafka:29092",
    "schema.history.internal.kafka.topic": "schemahistory.shard0",
    "database.connectionTimeZone": "Asia/Seoul"
  }
}'
```


2ë²ˆ ìƒ¤ë“œ
```http request
curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" localhost:8083/connectors/ -d '{
  "name": "inventory-connector-1",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "tasks.max": "1",
    "database.hostname": "mysql-3309", 
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "dbz",
    "database.server.id": "5002",
    "topic.prefix": "shard1",
    "database.include.list": "products",
    "schema.history.internal.kafka.bootstrap.servers": "kafka:29092",
    "schema.history.internal.kafka.topic": "schemahistory.shard1",
    "database.connectionTimeZone": "Asia/Seoul"
  }
}'
```


3ë²ˆ ìƒ¤ë“œ
```http request
curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" localhost:8083/connectors/ -d '{
  "name": "inventory-connector-2",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "tasks.max": "1",
    "database.hostname": "mysql-3310", 
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "dbz",
    "database.server.id": "5003",
    "topic.prefix": "shard2",
    "database.include.list": "products",
    "schema.history.internal.kafka.bootstrap.servers": "kafka:29092",
    "schema.history.internal.kafka.topic": "schemahistory.shard2",
    "database.connectionTimeZone": "Asia/Seoul"
  }
}'
```

# ì»¤ë„¥í„° ìƒíƒœ í™•ì¸(3ê°œ ëª¨ë‘ RUNNINGì´ì–´ì•¼ í•¨)
```http request
curl -s "localhost:8083/connectors?expand=status"
```

# ê¸°ì¡´ ì»¤ë„¥í„° ì‚­ì œ
```http request
curl -X DELETE localhost:8083/connectors/inventory-connector-0
curl -X DELETE localhost:8083/connectors/inventory-connector-1
curl -X DELETE localhost:8083/connectors/inventory-connector-2
```


# Kafka í† í”½ ìƒì„± í™•ì¸
```http request
docker exec -it docker-kafka-1 kafka-topics --list --bootstrap-server localhost:9092
```

